{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14967,
     "status": "ok",
     "timestamp": 1764536642213,
     "user": {
      "displayName": "장근혁",
      "userId": "11830411877105473042"
     },
     "user_tz": -540
    },
    "id": "C-JHhxGJPm2V",
    "outputId": "5a1329f6-7cab-4942-a4a3-9339ef1ee218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# prompt: 구글 마운트\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1764536688340,
     "user": {
      "displayName": "장근혁",
      "userId": "11830411877105473042"
     },
     "user_tz": -540
    },
    "id": "pcOBbeSgT6bG",
    "outputId": "b5ed5f80-0ba2-43f9-ce6a-d569b5f46666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/R2Gen\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/R2Gen_Llama27b_Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_w5b0-9LzUrV"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49327,
     "status": "ok",
     "timestamp": 1764536739748,
     "user": {
      "displayName": "장근혁",
      "userId": "11830411877105473042"
     },
     "user_tz": -540
    },
    "id": "nth2qb7_QBZX",
    "outputId": "e65c2d29-b036-4f2d-b495-4cf8d6ee6def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.3)\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.6)\n",
      "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.10.16)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pycocotools) (2.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cu126)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\n",
      "Requirement already satisfied: transformers>=4.40 in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.40) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.48.2\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install scikit-image\n",
    "!pip install matplotlib\n",
    "!pip install pycocotools\n",
    "!pip install pandas\n",
    "!pip install pillow\n",
    "!pip install tqdm\n",
    "!pip install numpy\n",
    "!pip install torch torchvision\n",
    "!pip install timm\n",
    "!pip install \"transformers>=4.40\" accelerate bitsandbytes sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 170165,
     "status": "ok",
     "timestamp": 1764536909915,
     "user": {
      "displayName": "장근혁",
      "userId": "11830411877105473042"
     },
     "user_tz": -540
    },
    "id": "v_WQ6P5tP1ZF",
    "outputId": "0ae0041c-097c-4ccd-a749-ef15b61310cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "\r0% [Connecting to archive.ubuntu.com (91.189.92.22)] [1 InRelease 2,588 B/129 k\r                                                                               \rHit:2 https://cli.github.com/packages stable InRelease\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
      "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,153 kB]\n",
      "Get:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
      "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,286 kB]\n",
      "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,491 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,008 kB]\n",
      "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,535 kB]\n",
      "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,836 kB]\n",
      "Hit:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,870 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,222 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,592 kB]\n",
      "Fetched 37.5 MB in 2min 36s (240 kB/s)\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  libnss-mdns fonts-dejavu-extra fonts-ipafont-gothic fonts-ipafont-mincho\n",
      "  fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic\n",
      "The following NEW packages will be installed:\n",
      "  openjdk-11-jre-headless\n",
      "0 upgraded, 1 newly installed, 0 to remove and 57 not upgraded.\n",
      "Need to get 42.6 MB of archives.\n",
      "After this operation, 176 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openjdk-11-jre-headless amd64 11.0.29+7-1ubuntu1~22.04 [42.6 MB]\n",
      "Fetched 42.6 MB in 2s (19.3 MB/s)\n",
      "Selecting previously unselected package openjdk-11-jre-headless:amd64.\n",
      "(Reading database ... 121713 files and directories currently installed.)\n",
      "Preparing to unpack .../openjdk-11-jre-headless_11.0.29+7-1ubuntu1~22.04_amd64.deb ...\n",
      "Unpacking openjdk-11-jre-headless:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
      "Setting up openjdk-11-jre-headless:amd64 (11.0.29+7-1ubuntu1~22.04) ...\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
      "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "!apt-get -y update\n",
    "!apt-get -y install openjdk-11-jre-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14983455,
     "status": "ok",
     "timestamp": 1764532028920,
     "user": {
      "displayName": "장근혁",
      "userId": "11830411877105473042"
     },
     "user_tz": -540
    },
    "id": "4k6asLizXvBF",
    "outputId": "4bcaca36-2cf5-4578-9c51-dd7e81d5cdb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100% 171M/171M [00:01<00:00, 129MB/s]\n",
      "tokenizer_config.json: 100% 776/776 [00:00<00:00, 6.16MB/s]\n",
      "tokenizer.model: 100% 500k/500k [00:00<00:00, 1.06MB/s]\n",
      "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 12.1MB/s]\n",
      "special_tokens_map.json: 100% 414/414 [00:00<00:00, 3.77MB/s]\n",
      "config.json: 100% 609/609 [00:00<00:00, 5.64MB/s]\n",
      "2025-11-30 15:37:48.527786: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-30 15:37:48.544535: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764517068.563326    1809 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764517068.568737    1809 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764517068.582996    1809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764517068.583019    1809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764517068.583022    1809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764517068.583025    1809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-30 15:37:48.587211: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 115MB/s]\n",
      "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
      "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:   0% 109k/9.98G [00:00<17:39:14, 157kB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   0% 11.0M/9.98G [00:00<08:57, 18.6MB/s] \u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   0% 1.55M/3.50G [00:00<31:08, 1.87MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:   1% 50.0M/9.98G [00:00<01:51, 89.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   0% 13.3M/3.50G [00:01<03:28, 16.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:   1% 71.3M/9.98G [00:01<01:32, 107MB/s] \u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   1% 44.1M/3.50G [00:01<00:56, 60.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   2% 59.3M/3.50G [00:01<00:44, 76.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   3% 93.4M/3.50G [00:01<00:26, 130MB/s] \u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:   1% 106M/9.98G [00:01<02:08, 76.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   3% 323M/9.98G [00:01<00:27, 352MB/s] \u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:   3% 122M/3.50G [00:01<00:35, 96.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  12% 409M/3.50G [00:01<00:05, 519MB/s] \u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:   5% 468M/9.98G [00:01<00:20, 468MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6% 594M/9.98G [00:02<00:17, 546MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  15% 515M/3.50G [00:02<00:06, 482MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  17% 594M/3.50G [00:02<00:05, 501MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:   7% 721M/9.98G [00:03<00:41, 225MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8% 804M/9.98G [00:04<00:50, 182MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  21% 729M/3.50G [00:04<00:18, 152MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  23% 800M/3.50G [00:06<00:29, 91.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:   9% 895M/9.98G [00:06<01:37, 93.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  24% 849M/3.50G [00:06<00:27, 96.0MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  10% 962M/9.98G [00:06<01:29, 101MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  10% 990M/9.98G [00:07<02:01, 74.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  25% 883M/3.50G [00:08<00:42, 61.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  27% 951M/3.50G [00:08<00:32, 77.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  10% 1.03G/9.98G [00:09<02:34, 57.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11% 1.10G/9.98G [00:09<02:03, 71.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12% 1.15G/9.98G [00:10<01:47, 82.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12% 1.18G/9.98G [00:10<01:43, 84.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12% 1.24G/9.98G [00:10<01:25, 102MB/s] \u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  28% 973M/3.50G [00:10<01:02, 40.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  30% 1.04G/3.50G [00:11<00:45, 54.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  33% 1.14G/3.50G [00:11<00:27, 87.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  13% 1.29G/9.98G [00:11<01:53, 76.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13% 1.32G/9.98G [00:11<01:46, 81.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14% 1.41G/9.98G [00:12<01:02, 138MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  14% 1.43G/9.98G [00:12<00:59, 145MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  33% 1.17G/3.50G [00:12<00:30, 75.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  15% 1.51G/9.98G [00:12<00:48, 176MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15% 1.54G/9.98G [00:12<00:55, 151MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  34% 1.19G/3.50G [00:13<00:38, 60.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  16% 1.62G/9.98G [00:13<00:45, 186MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  35% 1.22G/3.50G [00:14<00:53, 42.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  16% 1.64G/9.98G [00:14<01:51, 74.9MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  39% 1.36G/3.50G [00:14<00:24, 88.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  17% 1.66G/9.98G [00:15<03:02, 45.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17% 1.70G/9.98G [00:16<02:48, 49.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  40% 1.39G/3.50G [00:17<00:47, 44.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  17% 1.74G/9.98G [00:17<02:50, 48.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  41% 1.43G/3.50G [00:17<00:37, 55.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  42% 1.46G/3.50G [00:17<00:31, 65.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  43% 1.49G/3.50G [00:17<00:25, 79.2MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  18% 1.76G/9.98G [00:17<02:55, 46.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18% 1.79G/9.98G [00:18<03:06, 44.0MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  43% 1.52G/3.50G [00:18<00:32, 60.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  18% 1.81G/9.98G [00:19<02:50, 47.9MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  45% 1.56G/3.50G [00:19<00:32, 59.2MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  19% 1.91G/9.98G [00:19<01:41, 79.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19% 1.92G/9.98G [00:19<01:38, 81.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20% 1.98G/9.98G [00:20<01:27, 91.0MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  45% 1.59G/3.50G [00:20<00:44, 42.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  46% 1.62G/3.50G [00:20<00:37, 50.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  47% 1.64G/3.50G [00:21<00:33, 56.0MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  21% 2.05G/9.98G [00:21<01:39, 80.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21% 2.12G/9.98G [00:21<01:10, 112MB/s] \u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  48% 1.68G/3.50G [00:21<00:35, 52.0MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  22% 2.15G/9.98G [00:22<01:27, 89.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22% 2.24G/9.98G [00:22<00:55, 138MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  23% 2.31G/9.98G [00:22<00:50, 152MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23% 2.33G/9.98G [00:23<01:04, 119MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24% 2.39G/9.98G [00:23<00:54, 139MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  48% 1.69G/3.50G [00:23<01:02, 29.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  49% 1.70G/3.50G [00:24<01:11, 25.2MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  24% 2.44G/9.98G [00:24<01:21, 92.4MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  49% 1.72G/3.50G [00:24<01:02, 28.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  49% 1.72G/3.50G [00:24<01:00, 29.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  50% 1.73G/3.50G [00:24<00:55, 32.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  50% 1.75G/3.50G [00:25<00:37, 46.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 2.45G/9.98G [00:25<01:59, 63.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  51% 1.78G/3.50G [00:25<00:33, 50.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  52% 1.81G/3.50G [00:25<00:28, 59.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 2.48G/9.98G [00:26<02:25, 51.6MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  53% 1.86G/3.50G [00:26<00:19, 85.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 2.50G/9.98G [00:26<02:03, 60.4MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  53% 1.87G/3.50G [00:26<00:26, 60.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  54% 1.90G/3.50G [00:26<00:20, 76.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  55% 1.94G/3.50G [00:27<00:15, 98.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  56% 1.96G/3.50G [00:27<00:13, 110MB/s] \u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  25% 2.54G/9.98G [00:27<02:36, 47.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 2.58G/9.98G [00:27<02:03, 59.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 2.59G/9.98G [00:27<01:57, 62.7MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:28<00:31, 47.8MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 2.60G/9.98G [00:28<03:20, 36.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 2.61G/9.98G [00:29<03:51, 31.9MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  57% 1.99G/3.50G [00:29<00:52, 28.8MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 2.62G/9.98G [00:29<03:37, 33.9MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  58% 2.04G/3.50G [00:29<00:28, 50.9MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  26% 2.63G/9.98G [00:30<04:49, 25.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27% 2.65G/9.98G [00:30<03:31, 34.6MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27% 2.67G/9.98G [00:30<02:19, 52.4MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  59% 2.07G/3.50G [00:31<00:38, 37.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  60% 2.11G/3.50G [00:31<00:25, 53.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  27% 2.71G/9.98G [00:31<02:29, 48.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27% 2.73G/9.98G [00:31<02:38, 45.6MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  61% 2.13G/3.50G [00:32<00:36, 37.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  28% 2.76G/9.98G [00:32<02:24, 50.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28% 2.77G/9.98G [00:32<02:27, 48.9MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  63% 2.19G/3.50G [00:32<00:22, 58.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  28% 2.81G/9.98G [00:32<01:45, 67.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 2.88G/9.98G [00:33<01:16, 93.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  63% 2.21G/3.50G [00:33<00:32, 39.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  64% 2.25G/3.50G [00:34<00:22, 55.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  65% 2.27G/3.50G [00:34<00:19, 63.5MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 2.89G/9.98G [00:34<02:17, 51.4MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  67% 2.34G/3.50G [00:34<00:12, 95.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 2.92G/9.98G [00:34<02:03, 57.3MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 2.93G/9.98G [00:35<02:29, 47.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  67% 2.36G/3.50G [00:35<00:18, 62.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  29% 2.94G/9.98G [00:35<02:47, 42.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30% 2.95G/9.98G [00:35<02:31, 46.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30% 2.95G/9.98G [00:36<03:07, 37.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30% 2.96G/9.98G [00:36<03:15, 36.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30% 3.03G/9.98G [00:36<01:25, 81.5MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  69% 2.40G/3.50G [00:37<00:24, 44.1MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  31% 3.09G/9.98G [00:37<00:58, 119MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  31% 3.10G/9.98G [00:37<01:16, 89.9MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  69% 2.42G/3.50G [00:37<00:27, 38.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  70% 2.45G/3.50G [00:37<00:21, 48.5MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  32% 3.17G/9.98G [00:38<01:08, 99.3MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  72% 2.51G/3.50G [00:38<00:12, 79.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  32% 3.18G/9.98G [00:38<01:49, 62.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  72% 2.53G/3.50G [00:38<00:17, 55.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  33% 3.24G/9.98G [00:39<01:06, 101MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  33% 3.28G/9.98G [00:39<00:54, 123MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  74% 2.59G/3.50G [00:39<00:10, 88.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  34% 3.36G/9.98G [00:39<00:40, 164MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  75% 2.64G/3.50G [00:39<00:11, 77.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  34% 3.40G/9.98G [00:40<01:00, 109MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35% 3.45G/9.98G [00:40<00:51, 127MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35% 3.49G/9.98G [00:40<00:47, 136MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  77% 2.70G/3.50G [00:40<00:09, 81.1MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  35% 3.54G/9.98G [00:41<01:01, 105MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36% 3.60G/9.98G [00:41<00:59, 107MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37% 3.67G/9.98G [00:42<00:44, 140MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  79% 2.76G/3.50G [00:42<00:12, 59.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  80% 2.80G/3.50G [00:42<00:10, 67.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  82% 2.87G/3.50G [00:42<00:06, 96.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  37% 3.69G/9.98G [00:42<01:12, 86.4MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  83% 2.90G/3.50G [00:43<00:07, 81.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  37% 3.71G/9.98G [00:43<01:34, 66.5MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  85% 2.97G/3.50G [00:43<00:05, 103MB/s] \u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 3.77G/9.98G [00:43<01:10, 88.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 3.79G/9.98G [00:44<01:08, 89.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 3.80G/9.98G [00:44<01:24, 73.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38% 3.82G/9.98G [00:44<01:19, 77.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 3.87G/9.98G [00:45<01:01, 98.6MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  86% 2.99G/3.50G [00:45<00:09, 53.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 3.90G/9.98G [00:45<01:12, 84.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 3.91G/9.98G [00:45<01:24, 71.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 3.92G/9.98G [00:46<01:59, 50.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39% 3.93G/9.98G [00:46<02:06, 48.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 3.95G/9.98G [00:46<01:38, 61.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  86% 3.03G/3.50G [00:46<00:11, 39.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 3.97G/9.98G [00:47<01:35, 63.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 3.98G/9.98G [00:47<01:57, 51.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 3.98G/9.98G [00:47<01:55, 51.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 4.02G/9.98G [00:47<01:22, 72.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 4.03G/9.98G [00:48<01:50, 53.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40% 4.04G/9.98G [00:48<02:31, 39.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41% 4.04G/9.98G [00:49<03:12, 30.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41% 4.05G/9.98G [00:49<03:02, 32.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41% 4.05G/9.98G [00:49<02:54, 34.0MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  88% 3.08G/3.50G [00:49<00:15, 27.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  41% 4.09G/9.98G [00:50<02:17, 42.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42% 4.15G/9.98G [00:50<01:12, 79.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42% 4.16G/9.98G [00:50<01:13, 79.4MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42% 4.21G/9.98G [00:50<00:49, 116MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:51<00:48, 119MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:51<00:48, 117MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  89% 3.12G/3.50G [00:51<00:14, 26.2MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  43% 4.33G/9.98G [00:51<00:47, 119MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  93% 3.26G/3.50G [00:51<00:04, 57.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  95% 3.32G/3.50G [00:52<00:02, 71.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  44% 4.34G/9.98G [00:52<01:11, 79.2MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44% 4.36G/9.98G [00:53<01:38, 56.8MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:53<01:39, 56.0MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45% 4.45G/9.98G [00:53<01:06, 82.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45% 4.49G/9.98G [00:55<02:16, 40.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:55<00:03, 34.9MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00002.safetensors:  45% 4.53G/9.98G [00:56<01:36, 56.5MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46% 4.56G/9.98G [00:56<01:18, 68.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46% 4.58G/9.98G [00:56<01:36, 55.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46% 4.63G/9.98G [00:57<01:21, 65.9MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47% 4.66G/9.98G [00:57<01:12, 73.1MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47% 4.70G/9.98G [00:57<00:52, 100MB/s] \u001b[A\n",
      "\n",
      "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:57<00:00, 60.4MB/s]\n",
      "\n",
      "model-00001-of-00002.safetensors:  48% 4.77G/9.98G [00:58<00:36, 142MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48% 4.80G/9.98G [00:58<00:32, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49% 4.84G/9.98G [00:58<00:28, 178MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49% 4.92G/9.98G [00:58<00:30, 168MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 4.94G/9.98G [00:59<00:41, 120MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 5.00G/9.98G [00:59<00:38, 129MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50% 5.03G/9.98G [00:59<00:38, 127MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51% 5.09G/9.98G [01:00<00:27, 176MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52% 5.14G/9.98G [01:00<00:32, 150MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52% 5.22G/9.98G [01:00<00:22, 210MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 5.26G/9.98G [01:00<00:25, 182MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 5.28G/9.98G [01:01<00:40, 117MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53% 5.34G/9.98G [01:02<00:40, 114MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54% 5.36G/9.98G [01:02<00:38, 119MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54% 5.39G/9.98G [01:03<01:03, 71.7MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 5.46G/9.98G [01:03<00:38, 118MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 5.49G/9.98G [01:03<00:41, 107MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 5.51G/9.98G [01:03<00:41, 107MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55% 5.53G/9.98G [01:03<00:38, 116MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56% 5.60G/9.98G [01:04<00:27, 161MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57% 5.64G/9.98G [01:04<00:21, 201MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58% 5.75G/9.98G [01:04<00:12, 332MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58% 5.81G/9.98G [01:04<00:11, 355MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59% 5.87G/9.98G [01:04<00:10, 385MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60% 5.94G/9.98G [01:04<00:09, 435MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60% 6.00G/9.98G [01:04<00:09, 435MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61% 6.05G/9.98G [01:05<00:09, 434MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61% 6.10G/9.98G [01:05<00:09, 411MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62% 6.18G/9.98G [01:05<00:11, 326MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63% 6.24G/9.98G [01:05<00:09, 375MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64% 6.36G/9.98G [01:05<00:07, 513MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65% 6.44G/9.98G [01:05<00:06, 545MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65% 6.52G/9.98G [01:06<00:07, 479MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66% 6.61G/9.98G [01:06<00:06, 555MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67% 6.71G/9.98G [01:06<00:05, 634MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69% 6.84G/9.98G [01:06<00:04, 770MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70% 6.94G/9.98G [01:06<00:04, 692MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71% 7.04G/9.98G [01:08<00:22, 131MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72% 7.18G/9.98G [01:08<00:14, 194MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73% 7.32G/9.98G [01:09<00:09, 275MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75% 7.51G/9.98G [01:09<00:06, 403MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77% 7.63G/9.98G [01:09<00:04, 469MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78% 7.79G/9.98G [01:09<00:03, 596MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79% 7.92G/9.98G [01:09<00:04, 464MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80% 8.03G/9.98G [01:10<00:04, 403MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81% 8.13G/9.98G [01:10<00:05, 362MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82% 8.22G/9.98G [01:13<00:15, 116MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83% 8.30G/9.98G [01:13<00:11, 149MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85% 8.46G/9.98G [01:13<00:06, 227MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86% 8.54G/9.98G [01:13<00:06, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88% 8.73G/9.98G [01:13<00:03, 363MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89% 8.92G/9.98G [01:13<00:02, 516MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91% 9.09G/9.98G [01:14<00:01, 652MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93% 9.25G/9.98G [01:14<00:01, 472MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94% 9.37G/9.98G [01:15<00:01, 405MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95% 9.47G/9.98G [01:17<00:03, 142MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97% 9.66G/9.98G [01:17<00:01, 217MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99% 9.85G/9.98G [01:17<00:00, 316MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [01:22<00:00, 121MB/s] \n",
      "Fetching 2 files: 100% 2/2 [01:22<00:00, 41.32s/it]\n",
      "Loading checkpoint shards: 100% 2/2 [00:15<00:00,  7.78s/it]\n",
      "generation_config.json: 100% 188/188 [00:00<00:00, 1.86MB/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 1\n",
      "\ttrain_loss     : 1.7510447304982406\n",
      "\tval_BLEU_1     : 0.33645432271610637\n",
      "\tval_BLEU_2     : 0.19390394616782225\n",
      "\tval_BLEU_3     : 0.13100657766344537\n",
      "\tval_BLEU_4     : 0.09117923119339699\n",
      "\tval_ROUGE_L    : 0.29196522591648677\n",
      "\ttest_BLEU_1    : 0.33454971979667514\n",
      "\ttest_BLEU_2    : 0.20090432023759877\n",
      "\ttest_BLEU_3    : 0.13715460927312947\n",
      "\ttest_BLEU_4    : 0.09577595474882723\n",
      "\ttest_ROUGE_L   : 0.3062416544178958\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 2\n",
      "\ttrain_loss     : 0.9896118407066051\n",
      "\tval_BLEU_1     : 0.34589017875706657\n",
      "\tval_BLEU_2     : 0.2028430145670532\n",
      "\tval_BLEU_3     : 0.13433447649350905\n",
      "\tval_BLEU_4     : 0.09223162669230194\n",
      "\tval_ROUGE_L    : 0.31611075518706594\n",
      "\ttest_BLEU_1    : 0.3778004025854187\n",
      "\ttest_BLEU_2    : 0.22953574597194512\n",
      "\ttest_BLEU_3    : 0.15623860590815258\n",
      "\ttest_BLEU_4    : 0.10910178664524664\n",
      "\ttest_ROUGE_L   : 0.338264486097742\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 3\n",
      "\ttrain_loss     : 0.8984638168261602\n",
      "\tval_BLEU_1     : 0.3489045827214028\n",
      "\tval_BLEU_2     : 0.23558467431353802\n",
      "\tval_BLEU_3     : 0.16198362513583398\n",
      "\tval_BLEU_4     : 0.11385051630634008\n",
      "\tval_ROUGE_L    : 0.35762274018308576\n",
      "\ttest_BLEU_1    : 0.39410889550764494\n",
      "\ttest_BLEU_2    : 0.26783588903276434\n",
      "\ttest_BLEU_3    : 0.18708505865949882\n",
      "\ttest_BLEU_4    : 0.13262108736039283\n",
      "\ttest_ROUGE_L   : 0.3761610459122536\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 4\n",
      "\ttrain_loss     : 0.8246744582286247\n",
      "\tval_BLEU_1     : 0.4270414154614461\n",
      "\tval_BLEU_2     : 0.2729912029763183\n",
      "\tval_BLEU_3     : 0.18905795492938274\n",
      "\tval_BLEU_4     : 0.13523137365163374\n",
      "\tval_ROUGE_L    : 0.3550594017340347\n",
      "\ttest_BLEU_1    : 0.4600774907188114\n",
      "\ttest_BLEU_2    : 0.29334481147136043\n",
      "\ttest_BLEU_3    : 0.20433535853446638\n",
      "\ttest_BLEU_4    : 0.14879916869563364\n",
      "\ttest_ROUGE_L   : 0.36750867590548736\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 5\n",
      "\ttrain_loss     : 0.7626813732660733\n",
      "\tval_BLEU_1     : 0.44239028944907166\n",
      "\tval_BLEU_2     : 0.27358794552035604\n",
      "\tval_BLEU_3     : 0.18125849673748742\n",
      "\tval_BLEU_4     : 0.12494828836668812\n",
      "\tval_ROUGE_L    : 0.3434225678173864\n",
      "\ttest_BLEU_1    : 0.4389305635698962\n",
      "\ttest_BLEU_2    : 0.27284423960043874\n",
      "\ttest_BLEU_3    : 0.18304315549294806\n",
      "\ttest_BLEU_4    : 0.1273115042522522\n",
      "\ttest_ROUGE_L   : 0.35419305313192195\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 6\n",
      "\ttrain_loss     : 0.7194820296305876\n",
      "\tval_BLEU_1     : 0.4502985137484678\n",
      "\tval_BLEU_2     : 0.28453354613241877\n",
      "\tval_BLEU_3     : 0.19928242806020036\n",
      "\tval_BLEU_4     : 0.1466553841244026\n",
      "\tval_ROUGE_L    : 0.3491681860453378\n",
      "\ttest_BLEU_1    : 0.45071130548431854\n",
      "\ttest_BLEU_2    : 0.28615721705793473\n",
      "\ttest_BLEU_3    : 0.20169219258501866\n",
      "\ttest_BLEU_4    : 0.14945301867508884\n",
      "\ttest_ROUGE_L   : 0.35968919329805404\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "Saving current best: model_best.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 7\n",
      "\ttrain_loss     : 0.6820859950322371\n",
      "\tval_BLEU_1     : 0.42162836180440144\n",
      "\tval_BLEU_2     : 0.27166637963165047\n",
      "\tval_BLEU_3     : 0.17962373124342737\n",
      "\tval_BLEU_4     : 0.12416040168819122\n",
      "\tval_ROUGE_L    : 0.34864962750838674\n",
      "\ttest_BLEU_1    : 0.45252174037968323\n",
      "\ttest_BLEU_2    : 0.28908448021510813\n",
      "\ttest_BLEU_3    : 0.1924749992291659\n",
      "\ttest_BLEU_4    : 0.13435796421706614\n",
      "\ttest_ROUGE_L   : 0.3576890296924067\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 8\n",
      "\ttrain_loss     : 0.6595399384315197\n",
      "\tval_BLEU_1     : 0.3527713647452087\n",
      "\tval_BLEU_2     : 0.22462539068851206\n",
      "\tval_BLEU_3     : 0.15486942337025814\n",
      "\tval_BLEU_4     : 0.11240277290504096\n",
      "\tval_ROUGE_L    : 0.3435102971978223\n",
      "\ttest_BLEU_1    : 0.4014284709407255\n",
      "\ttest_BLEU_2    : 0.25998714532295686\n",
      "\ttest_BLEU_3    : 0.18194036753688728\n",
      "\ttest_BLEU_4    : 0.1324900087099816\n",
      "\ttest_ROUGE_L   : 0.36252055693190505\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 9\n",
      "\ttrain_loss     : 0.6423731343104289\n",
      "\tval_BLEU_1     : 0.38887117572290897\n",
      "\tval_BLEU_2     : 0.24984600927565587\n",
      "\tval_BLEU_3     : 0.1718414339295691\n",
      "\tval_BLEU_4     : 0.12229681214533807\n",
      "\tval_ROUGE_L    : 0.35592822260658974\n",
      "\ttest_BLEU_1    : 0.4485112568122852\n",
      "\ttest_BLEU_2    : 0.2932775188850101\n",
      "\ttest_BLEU_3    : 0.2064086549566513\n",
      "\ttest_BLEU_4    : 0.1498852326952733\n",
      "\ttest_ROUGE_L   : 0.37796338013567765\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 10\n",
      "\ttrain_loss     : 0.632797138278301\n",
      "\tval_BLEU_1     : 0.2446670132064797\n",
      "\tval_BLEU_2     : 0.15146661271464432\n",
      "\tval_BLEU_3     : 0.10721027715832186\n",
      "\tval_BLEU_4     : 0.0807351824706025\n",
      "\tval_ROUGE_L    : 0.3236512201404212\n",
      "\ttest_BLEU_1    : 0.29100925679253364\n",
      "\ttest_BLEU_2    : 0.18237952279794373\n",
      "\ttest_BLEU_3    : 0.12909498425402788\n",
      "\ttest_BLEU_4    : 0.09634641401774185\n",
      "\ttest_ROUGE_L   : 0.34618925417776125\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 11\n",
      "\ttrain_loss     : 0.6086332383064124\n",
      "\tval_BLEU_1     : 0.3513191901597086\n",
      "\tval_BLEU_2     : 0.2303409645760258\n",
      "\tval_BLEU_3     : 0.16384423418797053\n",
      "\tval_BLEU_4     : 0.1210743551151453\n",
      "\tval_ROUGE_L    : 0.34674000174161534\n",
      "\ttest_BLEU_1    : 0.3741531996308642\n",
      "\ttest_BLEU_2    : 0.2516926432509732\n",
      "\ttest_BLEU_3    : 0.1859642886226926\n",
      "\ttest_BLEU_4    : 0.14205669784793618\n",
      "\ttest_ROUGE_L   : 0.3647917772950464\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 12\n",
      "\ttrain_loss     : 0.6032845804324517\n",
      "\tval_BLEU_1     : 0.3101287915417622\n",
      "\tval_BLEU_2     : 0.19240307123534292\n",
      "\tval_BLEU_3     : 0.13496511719378743\n",
      "\tval_BLEU_4     : 0.10078862953156974\n",
      "\tval_ROUGE_L    : 0.32230806849638394\n",
      "\ttest_BLEU_1    : 0.36336243271803415\n",
      "\ttest_BLEU_2    : 0.22831105275373467\n",
      "\ttest_BLEU_3    : 0.16072213666128332\n",
      "\ttest_BLEU_4    : 0.11864348888459017\n",
      "\ttest_ROUGE_L   : 0.34048999660409274\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 13\n",
      "\ttrain_loss     : 0.5914963772663704\n",
      "\tval_BLEU_1     : 0.4463898085779522\n",
      "\tval_BLEU_2     : 0.2852512079456764\n",
      "\tval_BLEU_3     : 0.19859655373660423\n",
      "\tval_BLEU_4     : 0.14480275986774685\n",
      "\tval_ROUGE_L    : 0.35467458655770734\n",
      "\ttest_BLEU_1    : 0.49229309066202853\n",
      "\ttest_BLEU_2    : 0.3174929903520922\n",
      "\ttest_BLEU_3    : 0.22549507934765747\n",
      "\ttest_BLEU_4    : 0.16765188461574718\n",
      "\ttest_ROUGE_L   : 0.38003738784960683\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 14\n",
      "\ttrain_loss     : 0.5851104156329081\n",
      "\tval_BLEU_1     : 0.32870091741631924\n",
      "\tval_BLEU_2     : 0.2062064162957069\n",
      "\tval_BLEU_3     : 0.1461063549331073\n",
      "\tval_BLEU_4     : 0.11020659627404673\n",
      "\tval_ROUGE_L    : 0.3315369521237861\n",
      "\ttest_BLEU_1    : 0.3878908304132578\n",
      "\ttest_BLEU_2    : 0.2530146602718564\n",
      "\ttest_BLEU_3    : 0.18425118263025228\n",
      "\ttest_BLEU_4    : 0.1414226675317968\n",
      "\ttest_ROUGE_L   : 0.35783593721708923\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\tepoch          : 15\n",
      "\ttrain_loss     : 0.577208630167521\n",
      "\tval_BLEU_1     : 0.3588664730362505\n",
      "\tval_BLEU_2     : 0.23159652040199225\n",
      "\tval_BLEU_3     : 0.16347226577868418\n",
      "\tval_BLEU_4     : 0.1203621755297933\n",
      "\tval_ROUGE_L    : 0.3427914504415231\n",
      "\ttest_BLEU_1    : 0.4058884490470996\n",
      "\ttest_BLEU_2    : 0.25911587137507974\n",
      "\ttest_BLEU_3    : 0.1834269195066751\n",
      "\ttest_BLEU_4    : 0.1360169748923173\n",
      "\ttest_ROUGE_L   : 0.3571831340389679\n",
      "Saving checkpoint: /content/drive/MyDrive/R2Gen_Llama27b/Results/current_checkpoint.pth ...\n",
      "Best results (w.r.t BLEU_4) in validation set:\n",
      "\tval_BLEU_4     : 0.1466553841244026\n",
      "\tepoch          : 6\n",
      "\ttrain_loss     : 0.7194820296305876\n",
      "\tval_BLEU_1     : 0.4502985137484678\n",
      "\tval_BLEU_2     : 0.28453354613241877\n",
      "\tval_BLEU_3     : 0.19928242806020036\n",
      "\tval_ROUGE_L    : 0.3491681860453378\n",
      "\ttest_BLEU_1    : 0.45071130548431854\n",
      "\ttest_BLEU_2    : 0.28615721705793473\n",
      "\ttest_BLEU_3    : 0.20169219258501866\n",
      "\ttest_BLEU_4    : 0.14945301867508884\n",
      "\ttest_ROUGE_L   : 0.35968919329805404\n",
      "Best results (w.r.t BLEU_4) in test set:\n",
      "\ttest_BLEU_4    : 0.16765188461574718\n",
      "\tepoch          : 13\n",
      "\ttrain_loss     : 0.5914963772663704\n",
      "\tval_BLEU_1     : 0.4463898085779522\n",
      "\tval_BLEU_2     : 0.2852512079456764\n",
      "\tval_BLEU_3     : 0.19859655373660423\n",
      "\tval_BLEU_4     : 0.14480275986774685\n",
      "\tval_ROUGE_L    : 0.35467458655770734\n",
      "\ttest_BLEU_1    : 0.49229309066202853\n",
      "\ttest_BLEU_2    : 0.3174929903520922\n",
      "\ttest_BLEU_3    : 0.22549507934765747\n",
      "\ttest_ROUGE_L   : 0.38003738784960683\n"
     ]
    }
   ],
   "source": [
    "!python main_train.py \\\n",
    "  --dataset_name iu_xray \\\n",
    "  --image_dir \"/content/drive/MyDrive/iu_xray/images\" \\\n",
    "  --ann_path \"/content/drive/MyDrive/iu_xray/annotation.json\" \\\n",
    "  --save_dir \"/content/drive/MyDrive/R2Gen_Llama27b/Results\" \\\n",
    "  --visual_extractor resnet101 \\\n",
    "  --epochs 15 \\\n",
    "  --decoder_type llama \\\n",
    "  --llama_model_name \"meta-llama/Llama-2-7b-hf\" \\\n",
    "  --llama_load_in_8bit \\\n",
    "  --freeze_llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 505464,
     "status": "ok",
     "timestamp": 1764537430007,
     "user": {
      "displayName": "장근혁",
      "userId": "11830411877105473042"
     },
     "user_tz": -540
    },
    "id": "xXG28MohaQg6",
    "outputId": "7bede872-c5e7-4285-f0e5-bf0756b31b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100% 171M/171M [00:01<00:00, 114MB/s]\n",
      "tokenizer_config.json: 100% 776/776 [00:00<00:00, 5.49MB/s]\n",
      "tokenizer.model: 100% 500k/500k [00:00<00:00, 1.03MB/s]\n",
      "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 11.1MB/s]\n",
      "special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.57MB/s]\n",
      "config.json: 100% 609/609 [00:00<00:00, 5.71MB/s]\n",
      "2025-11-30 21:09:09.962063: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-30 21:09:09.978790: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764536949.996749    6062 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764536950.002131    6062 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764536950.015917    6062 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764536950.015941    6062 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764536950.015944    6062 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764536950.015946    6062 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-30 21:09:10.020270: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 109MB/s]\n",
      "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
      "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   0% 389k/3.50G [00:00<1:53:16, 515kB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0% 18.0k/9.98G [00:00<133:07:41, 20.8kB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0% 3.04M/9.98G [00:00<39:48, 4.18MB/s]    \u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0% 17.2M/9.98G [00:01<06:21, 26.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   0% 40.7M/9.98G [00:01<02:43, 60.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1% 52.0M/9.98G [00:01<02:19, 71.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:   1% 18.7M/3.50G [00:01<03:36, 16.1MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   9% 326M/3.50G [00:01<00:09, 348MB/s]  \u001b[A\n",
      "model-00002-of-00002.safetensors:  13% 457M/3.50G [00:01<00:07, 419MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  17% 579M/3.50G [00:01<00:05, 532MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  20% 698M/3.50G [00:01<00:04, 609MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   1% 70.9M/9.98G [00:02<03:51, 42.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   5% 456M/9.98G [00:02<00:21, 445MB/s]  \u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   6% 582M/9.98G [00:02<00:17, 523MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  24% 855M/3.50G [00:02<00:05, 483MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  27% 950M/3.50G [00:02<00:04, 526MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  30% 1.05G/3.50G [00:02<00:04, 592MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  33% 1.14G/3.50G [00:02<00:04, 556MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  35% 1.23G/3.50G [00:03<00:08, 255MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7% 693M/9.98G [00:03<00:44, 209MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   7% 746M/9.98G [00:04<00:45, 203MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   8% 790M/9.98G [00:04<00:57, 160MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  38% 1.31G/3.50G [00:04<00:13, 157MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9% 869M/9.98G [00:04<00:50, 180MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  39% 1.35G/3.50G [00:04<00:12, 166MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:   9% 943M/9.98G [00:05<00:40, 222MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  41% 1.42G/3.50G [00:05<00:11, 185MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  10% 1.00G/9.98G [00:05<00:36, 247MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  11% 1.08G/9.98G [00:05<00:29, 304MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  42% 1.48G/3.50G [00:05<00:13, 153MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  44% 1.55G/3.50G [00:06<00:10, 179MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12% 1.16G/9.98G [00:06<01:05, 134MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  45% 1.58G/3.50G [00:06<00:16, 117MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  46% 1.60G/3.50G [00:07<00:18, 103MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  12% 1.20G/9.98G [00:07<01:25, 103MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13% 1.27G/9.98G [00:07<01:06, 131MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  47% 1.64G/3.50G [00:07<00:21, 85.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  13% 1.31G/9.98G [00:08<01:05, 132MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  47% 1.66G/3.50G [00:08<00:23, 78.8MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14% 1.35G/9.98G [00:08<01:07, 127MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14% 1.39G/9.98G [00:08<01:03, 135MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  48% 1.69G/3.50G [00:08<00:26, 68.7MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  14% 1.43G/9.98G [00:08<01:00, 142MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:08<00:15, 115MB/s] \u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15% 1.46G/9.98G [00:08<00:52, 161MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15% 1.50G/9.98G [00:09<00:45, 184MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  15% 1.54G/9.98G [00:09<00:44, 189MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  52% 1.83G/3.50G [00:09<00:14, 114MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  56% 1.97G/3.50G [00:09<00:08, 189MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16% 1.57G/9.98G [00:09<01:19, 105MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  57% 2.01G/3.50G [00:09<00:07, 202MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  16% 1.61G/9.98G [00:10<01:04, 129MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  59% 2.08G/3.50G [00:10<00:05, 240MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  61% 2.12G/3.50G [00:10<00:07, 192MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  61% 2.15G/3.50G [00:10<00:08, 164MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17% 1.66G/9.98G [00:10<01:29, 93.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  62% 2.18G/3.50G [00:10<00:07, 180MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17% 1.68G/9.98G [00:11<01:39, 83.3MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  63% 2.21G/3.50G [00:11<00:09, 143MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  64% 2.26G/3.50G [00:12<00:14, 87.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  17% 1.72G/9.98G [00:12<02:21, 58.5MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  66% 2.31G/3.50G [00:12<00:09, 119MB/s] \u001b[A\n",
      "model-00002-of-00002.safetensors:  67% 2.35G/3.50G [00:12<00:07, 146MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18% 1.76G/9.98G [00:12<02:01, 67.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  18% 1.79G/9.98G [00:12<01:34, 86.7MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  68% 2.38G/3.50G [00:12<00:09, 120MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  70% 2.45G/3.50G [00:13<00:06, 166MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19% 1.86G/9.98G [00:13<01:09, 118MB/s] \u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19% 1.89G/9.98G [00:13<01:13, 110MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19% 1.91G/9.98G [00:13<01:16, 105MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  71% 2.48G/3.50G [00:13<00:10, 96.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  19% 1.93G/9.98G [00:13<01:21, 99.0MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  72% 2.53G/3.50G [00:14<00:11, 85.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20% 1.98G/9.98G [00:14<01:24, 94.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  74% 2.58G/3.50G [00:14<00:09, 99.5MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  20% 2.04G/9.98G [00:14<01:10, 113MB/s] \u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21% 2.05G/9.98G [00:15<01:23, 94.4MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  76% 2.66G/3.50G [00:15<00:07, 119MB/s] \u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21% 2.09G/9.98G [00:15<01:12, 109MB/s] \u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  77% 2.69G/3.50G [00:15<00:05, 137MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  21% 2.13G/9.98G [00:15<01:03, 124MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22% 2.17G/9.98G [00:15<00:52, 149MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  79% 2.76G/3.50G [00:16<00:05, 131MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  80% 2.79G/3.50G [00:16<00:05, 138MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  22% 2.19G/9.98G [00:16<01:37, 79.6MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  81% 2.83G/3.50G [00:16<00:05, 111MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23% 2.26G/9.98G [00:17<01:17, 100MB/s] \u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  82% 2.85G/3.50G [00:17<00:06, 100MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  82% 2.88G/3.50G [00:17<00:05, 108MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23% 2.29G/9.98G [00:17<01:12, 107MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  84% 2.94G/3.50G [00:17<00:03, 157MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  23% 2.31G/9.98G [00:17<01:27, 88.1MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  85% 2.97G/3.50G [00:17<00:04, 121MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24% 2.38G/9.98G [00:17<00:56, 134MB/s] \u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  87% 3.03G/3.50G [00:18<00:02, 167MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  89% 3.10G/3.50G [00:18<00:01, 212MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24% 2.39G/9.98G [00:18<01:07, 113MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  90% 3.15G/3.50G [00:18<00:01, 210MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24% 2.42G/9.98G [00:18<01:19, 94.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  24% 2.43G/9.98G [00:18<01:18, 95.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25% 2.46G/9.98G [00:18<00:58, 128MB/s] \u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25% 2.49G/9.98G [00:18<00:51, 145MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  25% 2.54G/9.98G [00:19<00:42, 174MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  26% 2.64G/9.98G [00:19<00:25, 285MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  27% 2.68G/9.98G [00:19<00:26, 273MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  28% 2.76G/9.98G [00:19<00:30, 237MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29% 2.85G/9.98G [00:20<00:22, 313MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  29% 2.90G/9.98G [00:20<00:25, 272MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30% 2.97G/9.98G [00:20<00:21, 324MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  91% 3.19G/3.50G [00:20<00:05, 54.2MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  30% 3.02G/9.98G [00:20<00:35, 198MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  93% 3.25G/3.50G [00:21<00:03, 74.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31% 3.05G/9.98G [00:21<00:42, 162MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31% 3.08G/9.98G [00:21<00:46, 147MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:21<00:43, 159MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32% 3.15G/9.98G [00:21<00:41, 164MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32% 3.17G/9.98G [00:22<01:05, 104MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  32% 3.22G/9.98G [00:22<00:48, 140MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  33% 3.27G/9.98G [00:22<00:35, 190MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  95% 3.31G/3.50G [00:22<00:03, 53.8MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:23<00:01, 72.3MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34% 3.35G/9.98G [00:23<00:33, 201MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  34% 3.42G/9.98G [00:23<00:25, 262MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors:  98% 3.43G/3.50G [00:23<00:00, 92.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35% 3.46G/9.98G [00:23<00:23, 276MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35% 3.51G/9.98G [00:23<00:27, 234MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  35% 3.54G/9.98G [00:24<00:38, 167MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36% 3.57G/9.98G [00:24<00:37, 169MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  36% 3.63G/9.98G [00:24<00:39, 161MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  37% 3.71G/9.98G [00:24<00:33, 185MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38% 3.74G/9.98G [00:25<00:49, 125MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  38% 3.83G/9.98G [00:25<00:34, 181MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39% 3.85G/9.98G [00:26<00:38, 161MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  39% 3.91G/9.98G [00:26<00:30, 199MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:26<00:37, 159MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  40% 4.02G/9.98G [00:26<00:35, 166MB/s]\u001b[A\u001b[A\n",
      "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:27<00:00, 128MB/s] \n",
      "\n",
      "\n",
      "model-00001-of-00002.safetensors:  41% 4.04G/9.98G [00:27<00:53, 111MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  41% 4.13G/9.98G [00:27<00:31, 183MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  42% 4.20G/9.98G [00:27<00:24, 232MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43% 4.25G/9.98G [00:27<00:23, 248MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  43% 4.30G/9.98G [00:28<00:24, 231MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44% 4.34G/9.98G [00:28<00:23, 244MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44% 4.39G/9.98G [00:28<00:31, 180MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  44% 4.42G/9.98G [00:29<00:42, 132MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  45% 4.48G/9.98G [00:29<00:30, 181MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  46% 4.59G/9.98G [00:29<00:18, 296MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47% 4.69G/9.98G [00:30<00:23, 221MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  47% 4.74G/9.98G [00:30<00:21, 246MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  48% 4.83G/9.98G [00:30<00:18, 272MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  49% 4.89G/9.98G [00:30<00:16, 300MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50% 4.96G/9.98G [00:30<00:16, 300MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  50% 5.00G/9.98G [00:31<00:15, 318MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51% 5.07G/9.98G [00:31<00:24, 198MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  51% 5.13G/9.98G [00:31<00:20, 233MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  52% 5.17G/9.98G [00:31<00:20, 238MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53% 5.25G/9.98G [00:32<00:15, 315MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  53% 5.29G/9.98G [00:32<00:15, 309MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54% 5.35G/9.98G [00:32<00:15, 302MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  54% 5.43G/9.98G [00:32<00:18, 247MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  55% 5.46G/9.98G [00:32<00:17, 252MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56% 5.55G/9.98G [00:33<00:20, 220MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  56% 5.60G/9.98G [00:33<00:17, 245MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57% 5.66G/9.98G [00:33<00:15, 278MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  57% 5.72G/9.98G [00:33<00:12, 337MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  58% 5.77G/9.98G [00:34<00:16, 251MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59% 5.86G/9.98G [00:34<00:16, 253MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  59% 5.92G/9.98G [00:34<00:16, 250MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  60% 6.01G/9.98G [00:34<00:13, 296MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61% 6.04G/9.98G [00:35<00:15, 259MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61% 6.08G/9.98G [00:35<00:14, 272MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  61% 6.12G/9.98G [00:35<00:14, 266MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  62% 6.19G/9.98G [00:35<00:11, 340MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  63% 6.24G/9.98G [00:35<00:15, 247MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  63% 6.28G/9.98G [00:36<00:16, 226MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  63% 6.32G/9.98G [00:36<00:14, 255MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  64% 6.40G/9.98G [00:36<00:13, 273MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65% 6.47G/9.98G [00:36<00:10, 345MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  65% 6.53G/9.98G [00:37<00:19, 177MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  66% 6.63G/9.98G [00:37<00:12, 266MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  67% 6.70G/9.98G [00:37<00:10, 316MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  68% 6.79G/9.98G [00:37<00:09, 328MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  69% 6.87G/9.98G [00:37<00:08, 349MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70% 6.96G/9.98G [00:38<00:12, 237MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  70% 7.00G/9.98G [00:38<00:14, 209MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71% 7.05G/9.98G [00:39<00:12, 230MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  71% 7.10G/9.98G [00:39<00:11, 241MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72% 7.14G/9.98G [00:39<00:14, 202MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  72% 7.20G/9.98G [00:39<00:11, 244MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73% 7.24G/9.98G [00:39<00:10, 264MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73% 7.27G/9.98G [00:40<00:13, 206MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73% 7.30G/9.98G [00:40<00:14, 185MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  73% 7.32G/9.98G [00:40<00:18, 141MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  74% 7.40G/9.98G [00:40<00:11, 227MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75% 7.44G/9.98G [00:40<00:10, 249MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  75% 7.49G/9.98G [00:41<00:14, 175MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76% 7.54G/9.98G [00:41<00:15, 154MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  76% 7.59G/9.98G [00:41<00:14, 167MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77% 7.66G/9.98G [00:42<00:13, 178MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  77% 7.70G/9.98G [00:42<00:11, 199MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  78% 7.77G/9.98G [00:42<00:08, 258MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79% 7.84G/9.98G [00:42<00:07, 292MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  79% 7.88G/9.98G [00:42<00:07, 273MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80% 7.98G/9.98G [00:43<00:06, 326MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  80% 8.02G/9.98G [00:43<00:08, 221MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  81% 8.10G/9.98G [00:43<00:08, 224MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  82% 8.14G/9.98G [00:43<00:07, 252MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  82% 8.18G/9.98G [00:44<00:07, 238MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  83% 8.25G/9.98G [00:44<00:07, 216MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84% 8.33G/9.98G [00:44<00:06, 271MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  84% 8.38G/9.98G [00:44<00:06, 262MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85% 8.43G/9.98G [00:45<00:06, 245MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  85% 8.47G/9.98G [00:45<00:07, 190MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86% 8.55G/9.98G [00:45<00:07, 183MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  86% 8.60G/9.98G [00:46<00:08, 167MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  88% 8.77G/9.98G [00:46<00:03, 328MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  89% 8.87G/9.98G [00:47<00:04, 240MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90% 8.94G/9.98G [00:47<00:03, 271MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  90% 8.99G/9.98G [00:47<00:03, 270MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91% 9.04G/9.98G [00:47<00:03, 239MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  91% 9.09G/9.98G [00:48<00:05, 171MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  92% 9.15G/9.98G [00:48<00:04, 205MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  93% 9.24G/9.98G [00:48<00:02, 260MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  94% 9.33G/9.98G [00:48<00:01, 328MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95% 9.43G/9.98G [00:50<00:03, 141MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  95% 9.50G/9.98G [00:50<00:02, 165MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96% 9.55G/9.98G [00:50<00:02, 160MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  96% 9.61G/9.98G [00:51<00:02, 138MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  97% 9.68G/9.98G [00:52<00:03, 93.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  98% 9.74G/9.98G [00:53<00:02, 90.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  98% 9.79G/9.98G [00:54<00:02, 81.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99% 9.86G/9.98G [00:54<00:01, 97.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors:  99% 9.92G/9.98G [00:54<00:00, 123MB/s] \u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [00:55<00:00, 181MB/s]\n",
      "Fetching 2 files: 100% 2/2 [00:55<00:00, 27.62s/it]\n",
      "Loading checkpoint shards: 100% 2/2 [00:15<00:00,  7.80s/it]\n",
      "generation_config.json: 100% 188/188 [00:00<00:00, 1.53MB/s]\n",
      "0it [00:00, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "37it [05:34,  9.04s/it]\n",
      "{'test_BLEU_1': 0.39410889550764494, 'test_BLEU_2': 0.26783588903276434, 'test_BLEU_3': 0.18708505865949882, 'test_BLEU_4': 0.13262108736039283, 'test_ROUGE_L': np.float64(0.3761610459122536)}\n"
     ]
    }
   ],
   "source": [
    "!python main_test.py \\\n",
    "  --dataset_name iu_xray \\\n",
    "  --image_dir \"/content/drive/MyDrive/iu_xray/images\" \\\n",
    "  --ann_path \"/content/drive/MyDrive/iu_xray/annotation.json\" \\\n",
    "  --save_dir \"/content/drive/MyDrive/R2Gen_Llama27b/Results\" \\\n",
    "  --load \"/content/drive/MyDrive/R2Gen_Llama27b/Results/model_best.pth\" \\\n",
    "  --visual_extractor resnet101 \\\n",
    "  --decoder_type llama \\\n",
    "  --llama_model_name \"meta-llama/Llama-2-7b-hf\" \\\n",
    "  --llama_load_in_8bit \\\n",
    "  --freeze_llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 352630,
     "status": "ok",
     "timestamp": 1764537977101,
     "user": {
      "displayName": "장근혁",
      "userId": "11830411877105473042"
     },
     "user_tz": -540
    },
    "id": "FC6Os_yTuar2",
    "outputId": "4a8ff460-5f47-4b1f-9a3c-82b303f9099b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "2025-11-30 21:20:32.424524: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-30 21:20:32.442104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764537632.460514    9238 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764537632.465925    9238 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1764537632.480093    9238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764537632.480122    9238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764537632.480126    9238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1764537632.480128    9238 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-30 21:20:32.484372: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.16s/it]\n",
      "0it [00:00, ?it/s][ WARN:0@24.367] global loadsave.cpp:1063 imwrite_ Unsupported depth image for selected encoder is fallbacked to CV_8U.\n",
      "590it [05:22,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "!python main_plot.py \\\n",
    "  --dataset_name iu_xray \\\n",
    "  --image_dir \"/content/drive/MyDrive/iu_xray/images\" \\\n",
    "  --ann_path \"/content/drive/MyDrive/iu_xray/annotation.json\" \\\n",
    "  --save_dir \"/content/drive/MyDrive/R2Gen_Llama27b/Results\" \\\n",
    "  --load \"/content/drive/MyDrive/R2Gen_Llama27b/Results/model_best.pth\" \\\n",
    "  --visual_extractor resnet101 \\\n",
    "  --decoder_type llama"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
